# Guia Executivo de Valida√ß√£o - GNN-to-Knapsack

**Objetivo:** Executar todas as valida√ß√µes cient√≠ficas em ordem otimizada  
**Tempo total estimado:** 2-3 dias (execu√ß√£o + an√°lise)  
**Pr√©-requisito:** Modelo treinado em `checkpoints/run_20251020_104533`

---

## üéØ ORDEM DE EXECU√á√ÉO RECOMENDADA

### **DIA 1: Valida√ß√µes R√°pidas (5-6 horas)**

#### 1. Testar Repair (CR√çTICO - 1h)
```bash
cd /home/marcusvinicius/Void/GNN_to_Knapsack

# Testar novas estrat√©gias com repair
python experiments/pipelines/main.py evaluate \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --strategies sampling_repair warm_start_repair \
    --data-dir data/datasets

# Verificar se max_gap caiu de 9.41% para <2%
# Verificar se p95 ‚â§ 1%
```

**Crit√©rio de sucesso:**
- ‚úÖ max_gap < 2.0%
- ‚úÖ p95 < 1.0%
- ‚úÖ feasibility_rate = 100%

---

#### 2. An√°lise de Distribui√ß√£o (30 min)
```bash
# Analisar resultados existentes
python experiments/analysis/distribution_analysis.py \
    --results checkpoints/run_20251020_104533/evaluation/results_sampling.json \
    --output-dir checkpoints/run_20251020_104533/evaluation/distribution_analysis/sampling \
    --strategy sampling

# Repetir para warm_start
python experiments/analysis/distribution_analysis.py \
    --results checkpoints/run_20251020_104533/evaluation/results_warm_start.json \
    --output-dir checkpoints/run_20251020_104533/evaluation/distribution_analysis/warm_start \
    --strategy warm_start
```

**Output esperado:**
- CSV com estat√≠sticas por tamanho
- Plots: CDF, percentis, violin
- Sample size adequacy check

---

#### 3. Calibra√ß√£o (1h)
```bash
# Executar estudo de calibra√ß√£o
python experiments/analysis/calibration_study.py \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --val-data data/datasets/val.pkl \
    --test-data data/datasets/test.pkl \
    --output-dir checkpoints/run_20251020_104533/evaluation/calibration \
    --n-bins 10
```

**Crit√©rio de sucesso:**
- ‚úÖ ECE < 0.1 ap√≥s temperature ou Platt scaling
- ‚úÖ Reliability plot mostra boa calibra√ß√£o

---

#### 4. Diagn√≥sticos de Normaliza√ß√£o (30 min)
```bash
# Verificar invari√¢ncia a tamanho
python experiments/analysis/normalization_check.py \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --output-dir checkpoints/run_20251020_104533/evaluation/diagnostics \
    --sizes 10 25 50 100 \
    --n-instances-per-size 20
```

**Crit√©rio de sucesso:**
- ‚úÖ Features normalizadas em [0,1]
- ‚úÖ Sem satura√ß√£o em agregadores
- ‚úÖ Std(gap) consistente entre tamanhos

---

#### 5. Figura de Publica√ß√£o (5 min)
```bash
# Gerar figura 4-pain√©is
python experiments/pipelines/create_publication_figure.py \
    --results-dir checkpoints/run_20251020_104533/evaluation \
    --output-dir checkpoints/run_20251020_104533/evaluation/publication \
    --strategies sampling warm_start \
    --calibration-results checkpoints/run_20251020_104533/evaluation/calibration/calibration_results.json
```

**Output:**
- `figure_main.png` (16x12, 300 DPI)
- `table_results.tex`
- CSV por tamanho e estrat√©gia

---

### **DIA 2: In-Distribution Completa (3-4 horas)**

#### 6. Avalia√ß√£o In-Distribution Estruturada
```bash
# ATEN√á√ÉO: Isto gera novos datasets e roda 100 inst√¢ncias por tamanho
# Tempo estimado: 3-4 horas

python experiments/pipelines/in_distribution_validation.py \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --sizes 10 25 50 75 100 \
    --n-instances-per-size 100 \
    --strategies sampling sampling_repair \
    --output-dir checkpoints/run_20251020_104533/evaluation/in_dist_full \
    --seed 999
```

**O que acontece:**
1. Gera 500 novas inst√¢ncias (5 tamanhos √ó 100)
2. Resolve com OR-Tools (ground truth)
3. Avalia modelo em cada tamanho
4. Computa estat√≠sticas completas
5. Gera plots por tamanho
6. Roda an√°lise de distribui√ß√£o

**Crit√©rio de sucesso:**
- ‚úÖ p95 ‚â§ 1% para tamanhos 10, 25, 50
- ‚úÖ p95 ‚â§ 2% para tamanhos 75, 100
- ‚úÖ n‚â•50 em todos os bins (sample size adequado)

---

### **DIA 3: Ablation Study (1 dia - OPCIONAL)**

#### 7. Treinar e Comparar Arquiteturas
```bash
# ATEN√á√ÉO: Treina 9 modelos (3 arquiteturas √ó 3 profundidades)
# Tempo estimado: 6-8 horas em CPU, 2-3 horas em GPU

python experiments/pipelines/ablation_study_models.py \
    --data-dir data/datasets \
    --output-dir checkpoints/ablation \
    --models pna gcn gat \
    --depths 2 3 4 \
    --epochs 30 \
    --device cuda  # ou cpu
```

**O que acontece:**
1. Treina PNA com 2, 3, 4 layers
2. Treina GCN com 2, 3, 4 layers  
3. Treina GAT com 2, 3, 4 layers
4. Avalia cada modelo em test set
5. Gera tabela comparativa

**Crit√©rio de sucesso:**
- ‚úÖ PNA-3 domina em p95
- ‚úÖ Custo (tempo/par√¢metros) aceit√°vel

---

## üìä VALIDA√á√ÉO DOS RESULTADOS

Ap√≥s cada etapa, verifique:

### Depois do Repair (Etapa 1):
```bash
# Verificar JSON de resultados
cat checkpoints/run_20251020_104533/evaluation/results_sampling_repair.json | grep -E "mean_gap|p95|max_gap"

# Esperado:
# "mean_gap": 0.05,
# "max_gap": <2.0,
# p95 calculado < 1.0
```

### Depois da Calibra√ß√£o (Etapa 3):
```bash
cat checkpoints/run_20251020_104533/evaluation/calibration/calibration_results.json | grep -E "ece"

# Esperado:
# "ece": <0.1 (ap√≥s scaling)
```

### Depois da In-Distribution (Etapa 6):
```bash
cat checkpoints/run_20251020_104533/evaluation/in_dist_full/sampling/analysis/sampling_stats_by_size.json

# Verificar p95 por tamanho:
# {
#   "10": {"p95": <1.0},
#   "25": {"p95": <1.0},
#   "50": {"p95": <1.0},
#   ...
# }
```

---

## üéØ CRIT√âRIOS DE VALIDA√á√ÉO FINAL

Use este checklist para validar que tudo est√° pronto para publica√ß√£o:

### Estat√≠stica
- [ ] Bootstrap CI 95% calculado para todas as m√©tricas
- [ ] Sample size adequacy verificado (n‚â•50 por bin)
- [ ] Percentis p50/p90/p95/p99 reportados
- [ ] CDF plotada por tamanho

### Performance
- [ ] p95 ‚â§ 1% para tamanhos 10-50 ‚úÖ
- [ ] p95 ‚â§ 2% para tamanhos 51-100 ‚úÖ
- [ ] max_gap < 2% ap√≥s repair ‚úÖ
- [ ] feasibility_rate = 100% ‚úÖ

### Calibra√ß√£o
- [ ] ECE < 0.1 ap√≥s scaling ‚úÖ
- [ ] Reliability plot mostra boa calibra√ß√£o ‚úÖ
- [ ] Brier score reportado ‚úÖ

### Ablation
- [ ] PNA comparado com GCN e GAT ‚úÖ
- [ ] 2/3/4 layers comparado ‚úÖ
- [ ] PNA-3 layers demonstradamente superior ‚úÖ

### Visualiza√ß√£o
- [ ] Figura 4-pain√©is gerada (300 DPI) ‚úÖ
- [ ] Tabelas LaTeX prontas ‚úÖ
- [ ] CSV exportados ‚úÖ

---

## üö® TROUBLESHOOTING

### Erro: "Checkpoint not found"
```bash
# Verificar se checkpoint existe
ls -la checkpoints/run_20251020_104533/best_model.pt

# Se n√£o existir, ajustar --checkpoint-dir
```

### Erro: "Datasets not found"
```bash
# Verificar datasets
ls -la data/datasets/*.pkl

# Se n√£o existirem, gerar:
python experiments/pipelines/main.py full --generate-data
```

### Erro: "CUDA out of memory"
```bash
# Usar CPU ou reduzir batch size
python ... --device cpu --batch-size 16
```

### Plots n√£o aparecem (headless server)
```bash
# J√° configurado para salvar em arquivo
# Verificar output em: 
ls -la checkpoints/*/evaluation/*/*.png
```

---

## üìÅ ESTRUTURA DE OUTPUT FINAL

Ap√≥s executar tudo, voc√™ ter√°:

```
checkpoints/run_20251020_104533/evaluation/
‚îú‚îÄ‚îÄ results_sampling.json
‚îú‚îÄ‚îÄ results_sampling_repair.json
‚îú‚îÄ‚îÄ results_warm_start.json
‚îú‚îÄ‚îÄ results_warm_start_repair.json
‚îú‚îÄ‚îÄ distribution_analysis/
‚îÇ   ‚îú‚îÄ‚îÄ sampling/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sampling_stats_by_size.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sampling_cdf_by_size.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sampling_percentiles_by_size.png
‚îÇ   ‚îî‚îÄ‚îÄ warm_start/
‚îú‚îÄ‚îÄ calibration/
‚îÇ   ‚îú‚îÄ‚îÄ calibration_results.json
‚îÇ   ‚îî‚îÄ‚îÄ reliability_diagram.png
‚îú‚îÄ‚îÄ diagnostics/
‚îÇ   ‚îú‚îÄ‚îÄ feature_normalization.png
‚îÇ   ‚îú‚îÄ‚îÄ degree_histogram.png
‚îÇ   ‚îú‚îÄ‚îÄ aggregator_activations.png
‚îÇ   ‚îî‚îÄ‚îÄ gap_variance_by_size.png
‚îú‚îÄ‚îÄ in_dist_full/
‚îÇ   ‚îú‚îÄ‚îÄ sampling/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ results_n10.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ results_n25.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analysis/
‚îÇ   ‚îî‚îÄ‚îÄ sampling_repair/
‚îî‚îÄ‚îÄ publication/
    ‚îú‚îÄ‚îÄ figure_main.png           ‚≠ê FIGURA PRINCIPAL
    ‚îú‚îÄ‚îÄ table_results.tex         ‚≠ê TABELA LATEX
    ‚îú‚îÄ‚îÄ table_results_by_size.csv
    ‚îî‚îÄ‚îÄ table_results_by_strategy.csv

checkpoints/ablation/
‚îú‚îÄ‚îÄ pna_L2/
‚îú‚îÄ‚îÄ pna_L3/                       ‚≠ê MODELO BASELINE
‚îú‚îÄ‚îÄ pna_L4/
‚îú‚îÄ‚îÄ gcn_L2/
‚îú‚îÄ‚îÄ gcn_L3/
‚îú‚îÄ‚îÄ gcn_L4/
‚îú‚îÄ‚îÄ gat_L2/
‚îú‚îÄ‚îÄ gat_L3/
‚îú‚îÄ‚îÄ gat_L4/
‚îú‚îÄ‚îÄ ablation_results.csv          ‚≠ê COMPARA√á√ÉO
‚îî‚îÄ‚îÄ ablation_table.tex
```

---

## üéì PARA O PAPER

### Se√ß√£o Experimental - Conte√∫do Pronto

**4.1 Setup:**
```latex
We train on instances with 10-50 items (n=1000) and evaluate on 
200 test instances. All experiments use PNA with 3 layers and 
hidden dimension 64, trained for 50 epochs.
```

**4.2 Results:**
```latex
Table 1 (use ablation_table.tex):
    - Compara PNA vs GCN vs GAT
    - Mostra domin√¢ncia do PNA-3

Figure 1 (use figure_main.png):
    - Panel A: Gap vs tamanho (escalabilidade)
    - Panel B: CDF (distribui√ß√£o)
    - Panel C: Compara√ß√£o estrat√©gias
    - Panel D: Calibra√ß√£o

Table 2 (use table_results_by_size.csv):
    - Estat√≠sticas por tamanho
    - p50/p90/p95/p99 com CIs

Text:
    "Our method achieves median gap of 0% and p95 ‚â§ 0.54% on 
     in-distribution instances (10-50 items). After repair, 
     maximum gap reduces from 9.41% to <2%. Probability 
     calibration yields ECE=0.004 after Platt scaling."
```

---

## ‚úÖ CHECKLIST FINAL

Antes de submeter o paper:

- [ ] Todos os scripts executados sem erro
- [ ] Figuras geradas em alta resolu√ß√£o (300 DPI)
- [ ] Tabelas LaTeX compilam corretamente
- [ ] Todos os crit√©rios de valida√ß√£o atendidos
- [ ] C√≥digo commitado no Git
- [ ] README atualizado
- [ ] Resultados reproduz√≠veis (seed fixo)

---

## üöÄ COMANDO √öNICO (DEMO R√ÅPIDO)

Se voc√™ quer testar tudo rapidamente (sem treinar ablation):

```bash
#!/bin/bash
cd /home/marcusvinicius/Void/GNN_to_Knapsack

# 1. Repair (1h)
python experiments/pipelines/main.py evaluate \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --strategies sampling_repair warm_start_repair

# 2. An√°lise (30min)
python experiments/analysis/distribution_analysis.py \
    --results checkpoints/run_20251020_104533/evaluation/results_sampling.json \
    --output-dir checkpoints/run_20251020_104533/evaluation/distribution_analysis/sampling \
    --strategy sampling

# 3. Calibra√ß√£o (1h)
python experiments/analysis/calibration_study.py \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --val-data data/datasets/val.pkl \
    --test-data data/datasets/test.pkl \
    --output-dir checkpoints/run_20251020_104533/evaluation/calibration

# 4. Diagn√≥sticos (30min)
python experiments/analysis/normalization_check.py \
    --checkpoint-dir checkpoints/run_20251020_104533 \
    --output-dir checkpoints/run_20251020_104533/evaluation/diagnostics \
    --sizes 10 25 50 100

# 5. Figura Final (5min)
python experiments/pipelines/create_publication_figure.py \
    --results-dir checkpoints/run_20251020_104533/evaluation \
    --output-dir checkpoints/run_20251020_104533/evaluation/publication

echo "‚úÖ Valida√ß√£o r√°pida completa! Tempo total: ~3 horas"
```

---

**Fim do Guia Executivo**

üéØ Siga este roteiro e voc√™ ter√° evid√™ncia cient√≠fica **irrefut√°vel** em 2-3 dias.
